{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "from syft.store.blob_storage import BlobStorageConfig, BlobStorageClientConfig\n",
    "from syft.store.blob_storage.seaweedfs import SeaweedFSClient, SeaweedFSClientConfig\n",
    "from syft import ActionObject\n",
    "from syft.service.action.action_data_empty import ActionFileData\n",
    "from syft.service.queue.zmq_queue import ZMQQueueConfig, ZMQClientConfig\n",
    "from collections import defaultdict\n",
    "from syft.types.blob_storage import BlobFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging Protocol Changes...\n",
      "Data Migrated to latest version !!!\n",
      "Logged into <test-domain-helm2: High side Domain> as <info@openmined.org>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert-warning\" style=\"padding:5px;\"><strong>SyftWarning</strong>: You are using a default password. Please change the password using `[your_client].me.set_password([new_password])`.</div><br />"
      ],
      "text/plain": [
       "SyftWarning: You are using a default password. Please change the password using `[your_client].me.set_password([new_password])`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node = sy.orchestra.launch(name=\"test-domain-helm2\", dev_mode=True,\n",
    "                           reset=True,\n",
    "                           n_consumers=4,\n",
    "                           create_producer=True)\n",
    "client = node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: User 'A' successfully registered! To see users, run `[your_client].users`</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: User 'A' successfully registered! To see users, run `[your_client].users`"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.register(name=\"A\", email=\"a@b.org\", password=\"b\", password_verify=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run this with seaweed, but then you need to run the seaweed container manually and connect to it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run --entrypoint /bin/sh -p 8333:8333 -p 8888:8888 chrislusf/seaweedfs -c \"echo 's3.configure -access_key admin -secret_key admin -user iam -actions Read,Write,List,Tagging,Admin -apply' | weed shell > /dev/null 2>&1 & weed server -s3 -s3.port=8333 -master.volumeSizeLimitMB=2048\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob_config = BlobStorageConfig(client_type=SeaweedFSClient,\n",
    "#                                 client_config=SeaweedFSClientConfig(host=\"http://0.0.0.0\",\n",
    "#                                                                     port=\"8333\",\n",
    "#                                                                     access_key=\"admin\",\n",
    "#                                                                     secret_key=\"admin\",\n",
    "#                                                                     bucket_name=\"test_bucket\",\n",
    "#                                                                     region=\"us-east-1\"\n",
    "#                                                                    )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node.python_node.init_blob_storage(blob_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix way we send list of files\n",
    "scenario_objs = ActionObject.from_obj([\n",
    "    BlobFile.upload_from_path(\"scenario_data.jsonl\", client)\n",
    "])\n",
    "\n",
    "scenario_files_ptr = scenario_objs.send(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = ActionObject.from_obj([\n",
    "    BlobFile.upload_from_path(\"short_input.jsonl\", client)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_ptr = input_files.send(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_dataset = sy.Dataset(\n",
    "    name=\"Helm dataset\",\n",
    "    asset_list=[\n",
    "        sy.Asset(\n",
    "            name=\"helm train data\",\n",
    "            data=input_files_ptr,\n",
    "            mock=sy.ActionObject.empty()\n",
    "        ),\n",
    "        sy.Asset(\n",
    "            name=\"helm test data\",\n",
    "            data=scenario_files_ptr,\n",
    "            mock=sy.ActionObject.empty()\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████▌                                                    | 1/2 [00:00<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading: helm train data\n",
      "Uploading: helm test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Dataset uploaded to 'test-domain-helm2'. To see the datasets uploaded by a client on this node, use command `[your_client].datasets`</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Dataset uploaded to 'test-domain-helm2'. To see the datasets uploaded by a client on this node, use command `[your_client].datasets`"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upload_dataset(input_files_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_asset = client.datasets[\"Helm dataset\"].assets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_files_asset = client.datasets[\"Helm dataset\"].assets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syft functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Syft function 'compute_document_data_overlap' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`.</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Syft function 'compute_document_data_overlap' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sy.syft_function()\n",
    "def compute_document_data_overlap(domain, scenario_file, input_files, n):\n",
    "    print(\"starting overlap computation\")\n",
    "    from nltk import ngrams\n",
    "    from collections import defaultdict\n",
    "    from string import punctuation\n",
    "    import re, json\n",
    "\n",
    "    r = re.compile(r\"[\\s{}]+\".format(re.escape(punctuation)))\n",
    "    \n",
    "    def create_ngram_index(light_scenarios, n_values, stats_key_counts):\n",
    "        ngram_index = {n:{}  for n in n_values}\n",
    "        for scenario in light_scenarios:\n",
    "            for n in n_values:\n",
    "                stats_key = scenario['scenario_key'] + '_' + str(n)\n",
    "                stats_key_counts[stats_key] = len(scenario['instances'])\n",
    "                for instance in scenario['instances']:\n",
    "                    id = instance['id']                    \n",
    "                    input_tokens = r.split(instance['input'].lower())\n",
    "                    for input_ngram in ngrams(input_tokens, n):\n",
    "                        if input_ngram not in ngram_index[n]:\n",
    "                            ngram_index[n][input_ngram] = set()\n",
    "                        ngram_index[n][input_ngram].add(stats_key + '+' + id + '+' + 'input')\n",
    "\n",
    "                    # compute reference ngrams\n",
    "                    for reference in instance['references']:\n",
    "                        reference_unigrams = r.split(reference.lower())\n",
    "                        for reference_ngram in ngrams(reference_unigrams, n):\n",
    "                            if reference_ngram not in ngram_index[n]:\n",
    "                                ngram_index[n][reference_ngram] = set()\n",
    "                            ngram_index[n][reference_ngram].add(stats_key + '+' + id + '+' + 'references')\n",
    "        return ngram_index\n",
    "    \n",
    "    # # SETUP\n",
    "    print(\"preparing scenarios and creating indexes\")\n",
    "    light_scenarios = []\n",
    "    for light_scenario_json in scenario_file.iter_lines():\n",
    "        light_scenario_dict: dict = json.loads(light_scenario_json)\n",
    "\n",
    "        light_scenario_key_dict: dict = light_scenario_dict[\"scenario_key\"]\n",
    "        subject_spec = light_scenario_key_dict[\"scenario_spec\"]['args']['subject']\n",
    "        light_scenario_key = subject_spec + '_' + light_scenario_key_dict[\"split\"]\n",
    "        light_instances = [\n",
    "            {\n",
    "                'input': instance_dict['input'], \n",
    "                'references': instance_dict['references'], \n",
    "                'id': instance_dict[\"id\"]\n",
    "            }\n",
    "            for instance_dict in light_scenario_dict[\"instances\"]\n",
    "        ]\n",
    "        light_scenarios.append({'scenario_key': light_scenario_key, 'instances': light_instances})\n",
    "        \n",
    "    stats_key_counts = defaultdict(int)\n",
    "    \n",
    "    ngram_index = create_ngram_index(\n",
    "        light_scenarios=light_scenarios, n_values=[n], stats_key_counts=stats_key_counts\n",
    "    )\n",
    "    \n",
    "    r = re.compile(r\"[\\s{}]+\".format(re.escape(punctuation)))\n",
    "    stats_key_to_input_ids = defaultdict(set)\n",
    "    stats_key_to_reference_ids = defaultdict(set)\n",
    "    print(\"computing overlap\")\n",
    "    from time import sleep\n",
    "    sleep(1)\n",
    "    \n",
    "    domain.init_progress(input_files[0].file_size)\n",
    "\n",
    "    for input_file in input_files:\n",
    "        for bytes_read, line in input_file.iter_lines(progress=True):\n",
    "            sleep(1)\n",
    "            document = json.loads(line)[\"text\"]\n",
    "            document_tokens = r.split(document.lower())\n",
    "            for n in ngram_index.keys():\n",
    "                for document_ngram in ngrams(document_tokens, n):\n",
    "                    if document_ngram in ngram_index[n]:\n",
    "                        for entry_overlap_key in ngram_index[n][document_ngram]:\n",
    "                            stats_key, id, part = entry_overlap_key.split(\"+\")\n",
    "                            if part == \"input\":\n",
    "                                stats_key_to_input_ids[stats_key].add(id)\n",
    "                            elif part == \"references\":\n",
    "                                stats_key_to_reference_ids[stats_key].add(id)\n",
    "            domain.set_progress(bytes_read)\n",
    "    print(\"done\")\n",
    "    \n",
    "    return stats_key_to_input_ids, stats_key_to_reference_ids, stats_key_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: User Code Submitted</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: User Code Submitted"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.code.submit(compute_document_data_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Syft function 'main_function' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`.</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Syft function 'main_function' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sy.syft_function_single_use(input_files=input_files_asset, scenario_files=scenario_files_asset)\n",
    "def main_function(domain, input_files, scenario_files):\n",
    "    N = [5, 9, 13]\n",
    "    jobs = []\n",
    "    for n in N[:1]:\n",
    "        for scenario_file in scenario_files:\n",
    "            batch_job = domain.launch_job(\n",
    "                compute_document_data_overlap,\n",
    "                scenario_file=scenario_file,\n",
    "                input_files=input_files,\n",
    "                n=n\n",
    "            )\n",
    "            jobs.append(batch_job)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request approved for domain test-domain-helm2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Request 09c6aa5eb6614e1087a1ce8eecd6e79d changes applied</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Request 09c6aa5eb6614e1087a1ce8eecd6e79d changes applied"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.code.request_code_execution(main_function)\n",
    "client.requests[-1].approve(approve_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.code.main_function(input_files=input_files_asset,\n",
    "                                scenario_files=scenario_files_asset,\n",
    "                                blocking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[]"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.subjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting overlap computation\n",
      "preparing scenarios and creating indexes\n",
      "computing overlap\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job.subjobs[0].logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/12/23 13:08:32 FUNCTION LOG (734ad4b874294054a81d7ae680361e0b): done\n"
     ]
    }
   ],
   "source": [
    "results = [j.wait().get() for j in job.subjobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[(defaultdict(&lt;class &#x27;set&#x27;&gt;, {&#x27;philosophy_test_5&#x27;: {&#x27;id328&#x27;}, &#x27;philosophy_valid_5&#x27;: {&#x27;id12&#x27;}}), defaultdict(&lt;class &#x27;set&#x27;&gt;, {}), defaultdict(&lt;class &#x27;int&#x27;&gt;, {&#x27;philosophy_train_5&#x27;: 5, &#x27;philosophy_valid_5&#x27;: 34, &#x27;philosophy_test_5&#x27;: 311, &#x27;anatomy_train_5&#x27;: 5, &#x27;anatomy_valid_5&#x27;: 14, &#x27;anatomy_test_5&#x27;: 135}))]"
      ],
      "text/plain": [
       "[(defaultdict(set,\n",
       "              {'philosophy_test_5': {'id328'},\n",
       "               'philosophy_valid_5': {'id12'}}),\n",
       "  defaultdict(set, {}),\n",
       "  defaultdict(int,\n",
       "              {'philosophy_train_5': 5,\n",
       "               'philosophy_valid_5': 34,\n",
       "               'philosophy_test_5': 311,\n",
       "               'anatomy_train_5': 5,\n",
       "               'anatomy_valid_5': 14,\n",
       "               'anatomy_test_5': 135}))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stats_key_to_input_ids, stats_key_to_reference_ids, stats_key_counts\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(defaultdict(&lt;class &#x27;set&#x27;&gt;, {&#x27;philosophy_test_5&#x27;: {&#x27;id328&#x27;}, &#x27;philosophy_valid_5&#x27;: {&#x27;id12&#x27;}}), defaultdict(&lt;class &#x27;set&#x27;&gt;, {}), defaultdict(&lt;class &#x27;int&#x27;&gt;, {&#x27;philosophy_train_5&#x27;: 5, &#x27;philosophy_valid_5&#x27;: 34, &#x27;philosophy_test_5&#x27;: 311, &#x27;anatomy_train_5&#x27;: 5, &#x27;anatomy_valid_5&#x27;: 14, &#x27;anatomy_test_5&#x27;: 135}))"
      ],
      "text/plain": [
       "(defaultdict(set,\n",
       "             {'philosophy_test_5': {'id328'}, 'philosophy_valid_5': {'id12'}}),\n",
       " defaultdict(set, {}),\n",
       " defaultdict(int,\n",
       "             {'philosophy_train_5': 5,\n",
       "              'philosophy_valid_5': 34,\n",
       "              'philosophy_test_5': 311,\n",
       "              'anatomy_train_5': 5,\n",
       "              'anatomy_valid_5': 14,\n",
       "              'anatomy_test_5': 135}))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_key_to_input_ids, stats_key_to_reference_ids, stats_key_counts = zip(*results)\n",
    "\n",
    "total_input_ids = defaultdict(set)\n",
    "total_reference_ids = defaultdict(set)\n",
    "total_stats_key_counts = defaultdict(int)\n",
    "\n",
    "for d in stats_key_counts:\n",
    "    for key, val in d.items():\n",
    "        total_stats_key_counts[key] += val\n",
    "\n",
    "\n",
    "for d in stats_key_to_input_ids:\n",
    "    for key in d:\n",
    "        new_set = set()\n",
    "        if key in total_input_ids:\n",
    "            new_set = total_input_ids[key]\n",
    "        new_set = new_set.union(d[key])\n",
    "        total_input_ids[key] = new_set\n",
    "\n",
    "for d in stats_key_to_reference_ids:\n",
    "    for key in d:\n",
    "        new_set = set()\n",
    "        if key in total_reference_ids:\n",
    "            new_set = total_reference_ids[key]\n",
    "        new_set = total_reference_ids[key].union(d[key])\n",
    "        total_reference_ids[key] = new_set\n",
    "\n",
    "all_data_overlap_stats = []\n",
    "for stats_key, count in total_stats_key_counts.items():\n",
    "    data_overlap_stats = {\n",
    "        'data_overlap_stats_key': None,\n",
    "        'num_instances': count,\n",
    "        'instance_ids_with_overlapping_input': sorted(total_input_ids[stats_key]),\n",
    "        'instance_ids_with_overlapping_reference': sorted(total_reference_ids[stats_key]),\n",
    "    }\n",
    "    subject, split, n_str = stats_key.split('_')\n",
    "    data_overlap_stats['data_overlap_stats_key'] = {\n",
    "        'light_scenario_key': {'subject': subject, 'split': split},\n",
    "        'overlap_protocol_spec': {'n': int(n_str)}\n",
    "    }\n",
    "    all_data_overlap_stats.append(data_overlap_stats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'data_overlap_stats_key': {'light_scenario_key': {'split': 'train',\n",
      "                                                    'subject': 'philosophy'},\n",
      "                             'overlap_protocol_spec': {'n': 5}},\n",
      "  'instance_ids_with_overlapping_input': [],\n",
      "  'instance_ids_with_overlapping_reference': [],\n",
      "  'num_instances': 5},\n",
      " {'data_overlap_stats_key': {'light_scenario_key': {'split': 'valid',\n",
      "                                                    'subject': 'philosophy'},\n",
      "                             'overlap_protocol_spec': {'n': 5}},\n",
      "  'instance_ids_with_overlapping_input': ['id12'],\n",
      "  'instance_ids_with_overlapping_reference': [],\n",
      "  'num_instances': 34},\n",
      " {'data_overlap_stats_key': {'light_scenario_key': {'split': 'test',\n",
      "                                                    'subject': 'philosophy'},\n",
      "                             'overlap_protocol_spec': {'n': 5}},\n",
      "  'instance_ids_with_overlapping_input': ['id328'],\n",
      "  'instance_ids_with_overlapping_reference': [],\n",
      "  'num_instances': 311},\n",
      " {'data_overlap_stats_key': {'light_scenario_key': {'split': 'train',\n",
      "                                                    'subject': 'anatomy'},\n",
      "                             'overlap_protocol_spec': {'n': 5}},\n",
      "  'instance_ids_with_overlapping_input': [],\n",
      "  'instance_ids_with_overlapping_reference': [],\n",
      "  'num_instances': 5},\n",
      " {'data_overlap_stats_key': {'light_scenario_key': {'split': 'valid',\n",
      "                                                    'subject': 'anatomy'},\n",
      "                             'overlap_protocol_spec': {'n': 5}},\n",
      "  'instance_ids_with_overlapping_input': [],\n",
      "  'instance_ids_with_overlapping_reference': [],\n",
      "  'num_instances': 14},\n",
      " {'data_overlap_stats_key': {'light_scenario_key': {'split': 'test',\n",
      "                                                    'subject': 'anatomy'},\n",
      "                             'overlap_protocol_spec': {'n': 5}},\n",
      "  'instance_ids_with_overlapping_input': [],\n",
      "  'instance_ids_with_overlapping_reference': [],\n",
      "  'num_instances': 135}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(all_data_overlap_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
